{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 10264564,
     "sourceType": "datasetVersion",
     "datasetId": 6350166
    },
    {
     "sourceId": 10320107,
     "sourceType": "datasetVersion",
     "datasetId": 6389490
    }
   ],
   "dockerImageVersionId": 30822,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.metrics import f1_score\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks\nimport tensorflow.keras.backend as K\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-30T21:04:43.058012Z",
     "iopub.execute_input": "2024-12-30T21:04:43.058379Z",
     "iopub.status.idle": "2024-12-30T21:04:43.064915Z",
     "shell.execute_reply.started": "2024-12-30T21:04:43.058351Z",
     "shell.execute_reply": "2024-12-30T21:04:43.063724Z"
    }
   },
   "outputs": [],
   "execution_count": 216
  },
  {
   "cell_type": "code",
   "source": "train_path = \"/kaggle/input/african/Train.csv\"\ntest_path = \"/kaggle/input/african/Test.csv\"\neconomic_path = \"/kaggle/input/economic/economic_indicators.csv\"",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-30T21:04:43.066123Z",
     "iopub.execute_input": "2024-12-30T21:04:43.066416Z",
     "iopub.status.idle": "2024-12-30T21:04:43.086531Z",
     "shell.execute_reply.started": "2024-12-30T21:04:43.066392Z",
     "shell.execute_reply": "2024-12-30T21:04:43.085404Z"
    }
   },
   "outputs": [],
   "execution_count": 217
  },
  {
   "cell_type": "code",
   "source": "train = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)\nmacro_data = pd.read_csv(economic_path)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-30T21:04:43.088959Z",
     "iopub.execute_input": "2024-12-30T21:04:43.089322Z",
     "iopub.status.idle": "2024-12-30T21:04:43.346363Z",
     "shell.execute_reply.started": "2024-12-30T21:04:43.089290Z",
     "shell.execute_reply": "2024-12-30T21:04:43.345125Z"
    }
   },
   "outputs": [],
   "execution_count": 218
  },
  {
   "cell_type": "code",
   "source": "def impute_macro_indicators(df):\n    df = df[df['Country'] != \"Cote d'Ivoire\"].copy()\n    \n    df_long = pd.melt(\n        df,\n        id_vars=['Country', 'Indicator'],\n        value_vars=[col for col in df.columns if col.startswith('YR')],\n        var_name='Year',\n        value_name='Value'\n    )\n    \n    interest_indicators = [\n        'Interest rate spread (lending rate minus deposit rate, %)',\n        'Lending interest rate (%)',\n        'Real interest rate (%)',\n        'Deposit interest rate (%)'\n    ]\n    \n    for indicator in interest_indicators:\n        kenya_values = df_long[\n            (df_long['Country'] == 'Kenya') & \n            (df_long['Indicator'] == indicator)\n        ]['Value'].mean()\n        \n        mask = (\n            (df_long['Country'] == 'Ghana') & \n            (df_long['Indicator'] == indicator) &\n            (df_long['Value'].isna())\n        )\n        df_long.loc[mask, 'Value'] = kenya_values\n    \n    mask = df_long['Indicator'] == 'Fossil fuel energy consumption (% of total)'\n    df_long.loc[mask, 'Value'] = df_long.loc[mask].groupby('Country')['Value'].transform(\n        lambda x: x.fillna(method='ffill').fillna(method='bfill')\n    )\n    \n    mask = df_long['Indicator'] == 'Average precipitation in depth (mm per year)'\n    df_long.loc[mask, 'Value'] = df_long.loc[mask].groupby('Country')['Value'].transform(\n        lambda x: x.fillna(x.mean())\n    )\n    \n    df_wide = df_long.pivot_table(\n        index=['Country', 'Indicator'],\n        columns='Year',\n        values='Value'\n    ).reset_index()\n    \n    print(\"Missing values after imputation:\", df_wide.isna().sum().sum())\n    return df_wide\n\nmacro_data = impute_macro_indicators(macro_data)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-30T21:04:43.347603Z",
     "iopub.execute_input": "2024-12-30T21:04:43.347874Z",
     "iopub.status.idle": "2024-12-30T21:04:43.392153Z",
     "shell.execute_reply.started": "2024-12-30T21:04:43.347850Z",
     "shell.execute_reply": "2024-12-30T21:04:43.390957Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Missing values after imputation: 0\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "<ipython-input-219-4257637e9438>:34: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 219
  },
  {
   "cell_type": "code",
   "source": "def merge_with_nearest_year(data, macro_pivoted):\n    data = data.copy()\n    \n    merged_data = pd.DataFrame()\n    \n    # Get unique years in macro data\n    available_years = macro_pivoted['Year'].unique()\n    \n    # For each year in the loan data\n    for year in data['disbursement_year'].unique():\n        # Get the subset of data for this year\n        year_data = data[data['disbursement_year'] == year]\n        \n        # Find the nearest available year in macro data\n        nearest_year = min(available_years, key=lambda x: abs(x - year))\n        \n        # Merge with the nearest year data\n        macro_year = macro_pivoted[macro_pivoted['Year'] == nearest_year]\n        temp_merged = year_data.merge(\n            macro_year,\n            left_on=['country_id'],\n            right_on=['Country'],\n            how='left'\n        )\n        \n        merged_data = pd.concat([merged_data, temp_merged])\n    \n    # Drop the extra Country and Year columns\n    merged_data = merged_data.drop(['Country', 'Year'], axis=1)\n    \n    return merged_data",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-30T21:04:43.393860Z",
     "iopub.execute_input": "2024-12-30T21:04:43.394284Z",
     "iopub.status.idle": "2024-12-30T21:04:43.401202Z",
     "shell.execute_reply.started": "2024-12-30T21:04:43.394239Z",
     "shell.execute_reply": "2024-12-30T21:04:43.399956Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "execution_count": 220
  },
  {
   "cell_type": "code",
   "source": "def preprocess_data():\n    selected_indicators = [\n        # 'Inflation, consumer prices (annual %)',\n        'Unemployment rate',\n        # 'Lending interest rate (%)',\n        'Real interest rate (%)'\n    ]\n    \n    macro_long = pd.melt(\n        macro_data,\n        id_vars=['Country', 'Indicator'],\n        value_vars=[col for col in macro_data.columns if col.startswith('YR')],\n        var_name='Year',\n        value_name='Value'\n    )\n    \n    macro_long['Year'] = macro_long['Year'].str.replace('YR', '').astype(int)\n    \n    macro_filtered = macro_long[macro_long['Indicator'].isin(selected_indicators)]\n    macro_pivoted = macro_filtered.pivot_table(\n        index=['Country', 'Year'],\n        columns='Indicator',\n        values='Value'\n    ).reset_index()\n\n    data = pd.concat([train, test]).reset_index(drop=True)\n    data['disbursement_date'] = pd.to_datetime(data['disbursement_date'], errors='coerce')\n    data['due_date'] = pd.to_datetime(data['due_date'], errors='coerce')\n    \n    data['disbursement_year'] = data['disbursement_date'].dt.year\n    \n    data = merge_with_nearest_year(data, macro_pivoted)\n\n    date_cols = ['disbursement_date', 'due_date']\n    for col in date_cols:\n        data[col] = pd.to_datetime(data[col])\n        data[col+'_month'] = data[col].dt.month\n        data[col+'_day'] = data[col].dt.day\n        data[col+'_year'] = data[col].dt.year\n        data[f'loan_term_days'] = (data['due_date'] - data['disbursement_date']).dt.days\n        data[f'disbursement_weekday'] = data['disbursement_date'].dt.weekday\n        data[f'due_weekday'] = data['due_date'].dt.weekday\n    \n    data['repayment_ratio'] = data['Total_Amount_to_Repay'] / data['Total_Amount']\n    data['log_Total_Amount'] = np.log1p(data['Total_Amount'])\n    # data['interest_rate'] = (data['Total_Amount_to_Repay'] - data['Total_Amount']) / data['Total_Amount'] * 100\n    \n    # # Additional features using macro indicators\n    # data['real_vs_loan_interest_spread'] = data['interest_rate'] - data['Real interest rate (%)']\n\n    # data['loan_duration_years'] = (data['due_date'] - data['disbursement_date']).dt.days / 365.25\n    # data['inflation_adjusted_amount'] = data['Total_Amount'] / (\n    #     (1 + data['Inflation, consumer prices (annual %)'] / 100) ** data['loan_duration_years']\n    # )\n    \n    # Categorical encoding\n    cat_cols = data.select_dtypes(include='object').columns\n    data = pd.get_dummies(data, columns=['loan_type'], prefix='loan_type', drop_first=False)\n    loan_type_cols = [col for col in data.columns if col.startswith('loan_type_')]\n    data[loan_type_cols] = data[loan_type_cols].astype(int)\n    \n    le = LabelEncoder()\n    for col in [col for col in cat_cols if col not in ['loan_type', 'ID', 'Country']]:\n        data[col] = le.fit_transform(data[col])\n    \n    # Split back into train and test\n    train_df = data[data['ID'].isin(train['ID'].unique())]\n    test_df = data[data['ID'].isin(test['ID'].unique())]\n    \n    # Update features_for_modelling to include new macro features\n    features_for_modelling = [col for col in train_df.columns if col not in \n                            date_cols + ['ID', 'target', 'country_id', 'disbursement_year']]\n    \n    return train_df, test_df, features_for_modelling",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-30T21:04:43.402483Z",
     "iopub.execute_input": "2024-12-30T21:04:43.402870Z",
     "iopub.status.idle": "2024-12-30T21:04:43.427751Z",
     "shell.execute_reply.started": "2024-12-30T21:04:43.402836Z",
     "shell.execute_reply": "2024-12-30T21:04:43.426497Z"
    }
   },
   "outputs": [],
   "execution_count": 221
  },
  {
   "cell_type": "code",
   "source": "def f1_metric(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    \n    precision = true_positives / (predicted_positives + K.epsilon())\n    recall = true_positives / (possible_positives + K.epsilon())\n    \n    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n    return f1_val\n\ndef find_optimal_threshold(predictions, y_true):\n    thresholds = np.arange(0.1, 0.9, 0.02)\n    best_threshold = 0.5\n    best_f1 = 0.0\n    \n    for threshold in thresholds:\n        pred_labels = (predictions > threshold).astype(int)\n        f1 = f1_score(y_true, pred_labels)\n        if f1 > best_f1:\n            best_f1 = f1\n            best_threshold = threshold\n            \n    return best_threshold, best_f1",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-30T21:04:43.430886Z",
     "iopub.execute_input": "2024-12-30T21:04:43.431297Z",
     "iopub.status.idle": "2024-12-30T21:04:43.455880Z",
     "shell.execute_reply.started": "2024-12-30T21:04:43.431261Z",
     "shell.execute_reply": "2024-12-30T21:04:43.454650Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "execution_count": 222
  },
  {
   "cell_type": "code",
   "source": "def create_model(input_dim):\n    model = models.Sequential([\n        # Input layer\n        layers.Input(shape=(input_dim,)),\n        layers.BatchNormalization(),\n        \n        # First layer - increased capacity\n        layers.Dense(64, \n                    kernel_initializer='he_normal',\n                    kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n        layers.LeakyReLU(alpha=0.2),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3),\n        \n        # Second layer\n        layers.Dense(32,\n                    kernel_initializer='he_normal',\n                    kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n        layers.LeakyReLU(alpha=0.2),\n        layers.BatchNormalization(),\n        layers.Dropout(0.2),\n        \n        layers.Dense(1, activation='sigmoid',\n                    bias_initializer=tf.keras.initializers.Constant(np.log(956/50534)))\n    ])\n    return model\n\n\ndef train_with_kfold(X, y, features_for_modelling, n_splits=5):\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n    \n    # Initialize lists to store results\n    models = []\n    scalers = []\n    thresholds = []\n    f1_scores = []\n    \n    # Convert y to numpy array and ensure it's binary\n    y = np.array(y).astype(int)\n    \n    # For each fold\n    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n        print(f\"\\nTraining fold {fold + 1}/{n_splits}\")\n        \n        # Split data\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y[train_idx], y[val_idx]\n        \n        # Print class distribution for debugging\n        print(\"Training set class distribution:\", np.bincount(y_train))\n        print(\"Validation set class distribution:\", np.bincount(y_val))\n        \n        # Scale features\n        scaler = StandardScaler()\n        X_train_scaled = scaler.fit_transform(X_train)\n        X_val_scaled = scaler.transform(X_val)\n        \n        # Create and compile model\n        model = create_model(len(features_for_modelling))\n        model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n            loss='binary_crossentropy',\n            metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n        )\n        \n        # Calculate class weights\n        n_neg = np.sum(y_train == 0)\n        n_pos = np.sum(y_train == 1)\n        total = len(y_train)\n        \n        class_weights = {\n            0: total / (2.0 * n_neg),\n            1: total / (2.0 * n_pos)\n        }\n        \n        print(\"Class weights:\", class_weights)\n\n        early_stopping = callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=10,\n            restore_best_weights=True\n        )\n        \n        # Train model\n        history = model.fit(\n            X_train_scaled, y_train,\n            validation_data=(X_val_scaled, y_val),\n            epochs=60,\n            batch_size=128,\n            class_weight=class_weights,\n            callbacks=[early_stopping],\n            verbose=1\n        )\n        \n        # Find optimal threshold for this fold\n        val_pred = model.predict(X_val_scaled)\n        threshold, f1 = find_optimal_threshold(val_pred, y_val)\n        \n        print(f\"Fold {fold + 1} - Best threshold: {threshold:.3f}, F1-score: {f1:.4f}\")\n        \n        # Store results\n        models.append(model)\n        scalers.append(scaler)\n        thresholds.append(threshold)\n        f1_scores.append(f1)\n    \n    # Print summary\n    print(\"\\nCross-validation summary:\")\n    print(f\"Mean F1-score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n    print(f\"Mean threshold: {np.mean(thresholds):.4f} ± {np.std(thresholds):.4f}\")\n    \n    return models, scalers, thresholds, f1_scores",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-30T21:04:43.457505Z",
     "iopub.execute_input": "2024-12-30T21:04:43.457872Z",
     "iopub.status.idle": "2024-12-30T21:04:43.480790Z",
     "shell.execute_reply.started": "2024-12-30T21:04:43.457826Z",
     "shell.execute_reply": "2024-12-30T21:04:43.479508Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "execution_count": 223
  },
  {
   "cell_type": "code",
   "source": "train_df, test_df, features_for_modelling = preprocess_data()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-30T21:04:43.481799Z",
     "iopub.execute_input": "2024-12-30T21:04:43.482185Z",
     "iopub.status.idle": "2024-12-30T21:04:43.928988Z",
     "shell.execute_reply.started": "2024-12-30T21:04:43.482125Z",
     "shell.execute_reply": "2024-12-30T21:04:43.927747Z"
    }
   },
   "outputs": [],
   "execution_count": 224
  },
  {
   "cell_type": "code",
   "source": "X_train, X_val, y_train, y_val = train_test_split(\n    train_df[features_for_modelling], \n    train_df['target'], \n    random_state=42\n)\nprint(X_train.shape, X_val.shape, y_train.shape, y_val.shape)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-30T21:04:43.930210Z",
     "iopub.execute_input": "2024-12-30T21:04:43.930744Z",
     "iopub.status.idle": "2024-12-30T21:04:43.983827Z",
     "shell.execute_reply.started": "2024-12-30T21:04:43.930692Z",
     "shell.execute_reply": "2024-12-30T21:04:43.982572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "(51490, 47) (17164, 47) (51490,) (17164,)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 225
  },
  {
   "cell_type": "code",
   "source": "models, scalers, thresholds, f1_scores = train_with_kfold(\n    X_train, y_train, features_for_modelling\n)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-30T21:04:43.985072Z",
     "iopub.execute_input": "2024-12-30T21:04:43.985507Z",
     "iopub.status.idle": "2024-12-30T21:09:51.929733Z",
     "shell.execute_reply.started": "2024-12-30T21:04:43.985467Z",
     "shell.execute_reply": "2024-12-30T21:09:51.928484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\nTraining fold 1/5\nTraining set class distribution: [40453   739]\nValidation set class distribution: [10114   184]\nClass weights: {0: 0.5091340568066646, 1: 27.870094722598104}\nEpoch 1/60\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 5ms/step - accuracy: 0.9624 - auc: 0.8692 - loss: 2.5988 - val_accuracy: 0.9467 - val_auc: 0.9768 - val_loss: 1.5826\nEpoch 2/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9334 - auc: 0.9722 - loss: 1.5415 - val_accuracy: 0.9440 - val_auc: 0.9795 - val_loss: 1.2502\nEpoch 3/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9336 - auc: 0.9763 - loss: 1.2255 - val_accuracy: 0.9380 - val_auc: 0.9816 - val_loss: 1.0204\nEpoch 4/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9326 - auc: 0.9807 - loss: 0.9952 - val_accuracy: 0.9263 - val_auc: 0.9820 - val_loss: 0.8489\nEpoch 5/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9323 - auc: 0.9804 - loss: 0.8310 - val_accuracy: 0.9381 - val_auc: 0.9813 - val_loss: 0.6932\nEpoch 6/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9326 - auc: 0.9804 - loss: 0.7018 - val_accuracy: 0.9483 - val_auc: 0.9830 - val_loss: 0.5717\nEpoch 7/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9346 - auc: 0.9837 - loss: 0.5781 - val_accuracy: 0.9403 - val_auc: 0.9817 - val_loss: 0.4964\nEpoch 8/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9358 - auc: 0.9849 - loss: 0.4873 - val_accuracy: 0.9404 - val_auc: 0.9780 - val_loss: 0.4229\nEpoch 9/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9354 - auc: 0.9841 - loss: 0.4272 - val_accuracy: 0.9405 - val_auc: 0.9728 - val_loss: 0.3710\nEpoch 10/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9379 - auc: 0.9848 - loss: 0.3757 - val_accuracy: 0.9329 - val_auc: 0.9784 - val_loss: 0.3474\nEpoch 11/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9313 - auc: 0.9808 - loss: 0.3311 - val_accuracy: 0.9598 - val_auc: 0.9697 - val_loss: 0.2762\nEpoch 12/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9386 - auc: 0.9872 - loss: 0.2819 - val_accuracy: 0.9538 - val_auc: 0.9762 - val_loss: 0.2412\nEpoch 13/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9382 - auc: 0.9836 - loss: 0.2603 - val_accuracy: 0.9625 - val_auc: 0.9772 - val_loss: 0.2153\nEpoch 14/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9441 - auc: 0.9884 - loss: 0.2263 - val_accuracy: 0.9386 - val_auc: 0.9773 - val_loss: 0.2321\nEpoch 15/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9359 - auc: 0.9870 - loss: 0.2198 - val_accuracy: 0.9515 - val_auc: 0.9768 - val_loss: 0.2037\nEpoch 16/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9406 - auc: 0.9874 - loss: 0.2017 - val_accuracy: 0.9431 - val_auc: 0.9740 - val_loss: 0.2058\nEpoch 17/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9417 - auc: 0.9883 - loss: 0.1863 - val_accuracy: 0.9597 - val_auc: 0.9730 - val_loss: 0.1742\nEpoch 18/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9413 - auc: 0.9873 - loss: 0.1893 - val_accuracy: 0.9507 - val_auc: 0.9725 - val_loss: 0.1761\nEpoch 19/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9456 - auc: 0.9898 - loss: 0.1607 - val_accuracy: 0.9514 - val_auc: 0.9730 - val_loss: 0.1637\nEpoch 20/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9375 - auc: 0.9859 - loss: 0.1799 - val_accuracy: 0.9738 - val_auc: 0.9726 - val_loss: 0.1324\nEpoch 21/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9417 - auc: 0.9874 - loss: 0.1753 - val_accuracy: 0.9536 - val_auc: 0.9772 - val_loss: 0.1524\nEpoch 22/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 5ms/step - accuracy: 0.9453 - auc: 0.9877 - loss: 0.1622 - val_accuracy: 0.9402 - val_auc: 0.9680 - val_loss: 0.1617\nEpoch 23/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9401 - auc: 0.9859 - loss: 0.1742 - val_accuracy: 0.9351 - val_auc: 0.9698 - val_loss: 0.1691\nEpoch 24/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9416 - auc: 0.9888 - loss: 0.1551 - val_accuracy: 0.9281 - val_auc: 0.9721 - val_loss: 0.1946\nEpoch 25/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9390 - auc: 0.9885 - loss: 0.1521 - val_accuracy: 0.9548 - val_auc: 0.9775 - val_loss: 0.1346\nEpoch 26/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9365 - auc: 0.9838 - loss: 0.1620 - val_accuracy: 0.9747 - val_auc: 0.9746 - val_loss: 0.1192\nEpoch 27/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9459 - auc: 0.9887 - loss: 0.1548 - val_accuracy: 0.9707 - val_auc: 0.9703 - val_loss: 0.1190\nEpoch 28/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9462 - auc: 0.9889 - loss: 0.1471 - val_accuracy: 0.9575 - val_auc: 0.9691 - val_loss: 0.1314\nEpoch 29/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9451 - auc: 0.9889 - loss: 0.1429 - val_accuracy: 0.9576 - val_auc: 0.9724 - val_loss: 0.1417\nEpoch 30/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9456 - auc: 0.9896 - loss: 0.1414 - val_accuracy: 0.9450 - val_auc: 0.9726 - val_loss: 0.1499\nEpoch 31/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9468 - auc: 0.9904 - loss: 0.1330 - val_accuracy: 0.9492 - val_auc: 0.9789 - val_loss: 0.1485\nEpoch 32/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9439 - auc: 0.9894 - loss: 0.1422 - val_accuracy: 0.9643 - val_auc: 0.9798 - val_loss: 0.1203\nEpoch 33/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9475 - auc: 0.9900 - loss: 0.1383 - val_accuracy: 0.9590 - val_auc: 0.9745 - val_loss: 0.1226\nEpoch 34/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9449 - auc: 0.9887 - loss: 0.1476 - val_accuracy: 0.9542 - val_auc: 0.9751 - val_loss: 0.1382\nEpoch 35/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9475 - auc: 0.9915 - loss: 0.1256 - val_accuracy: 0.9406 - val_auc: 0.9783 - val_loss: 0.1628\nEpoch 36/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9429 - auc: 0.9895 - loss: 0.1398 - val_accuracy: 0.9634 - val_auc: 0.9788 - val_loss: 0.1359\nEpoch 37/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9483 - auc: 0.9891 - loss: 0.1361 - val_accuracy: 0.9646 - val_auc: 0.9799 - val_loss: 0.1206\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\nFold 1 - Best threshold: 0.760, F1-score: 0.6696\n\nTraining fold 2/5\nTraining set class distribution: [40453   739]\nValidation set class distribution: [10114   184]\nClass weights: {0: 0.5091340568066646, 1: 27.870094722598104}\nEpoch 1/60\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 5ms/step - accuracy: 0.9509 - auc: 0.7850 - loss: 2.9316 - val_accuracy: 0.9262 - val_auc: 0.9704 - val_loss: 1.7121\nEpoch 2/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9283 - auc: 0.9738 - loss: 1.6377 - val_accuracy: 0.9291 - val_auc: 0.9854 - val_loss: 1.3768\nEpoch 3/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9267 - auc: 0.9726 - loss: 1.3432 - val_accuracy: 0.9289 - val_auc: 0.9890 - val_loss: 1.1422\nEpoch 4/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9290 - auc: 0.9764 - loss: 1.1139 - val_accuracy: 0.9226 - val_auc: 0.9880 - val_loss: 0.9752\nEpoch 5/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9227 - auc: 0.9714 - loss: 0.9653 - val_accuracy: 0.9412 - val_auc: 0.9907 - val_loss: 0.7805\nEpoch 6/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9286 - auc: 0.9788 - loss: 0.8008 - val_accuracy: 0.9416 - val_auc: 0.9912 - val_loss: 0.6726\nEpoch 7/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9305 - auc: 0.9796 - loss: 0.6805 - val_accuracy: 0.9412 - val_auc: 0.9909 - val_loss: 0.5687\nEpoch 8/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9283 - auc: 0.9806 - loss: 0.5887 - val_accuracy: 0.9411 - val_auc: 0.9906 - val_loss: 0.4973\nEpoch 9/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9334 - auc: 0.9845 - loss: 0.4900 - val_accuracy: 0.9443 - val_auc: 0.9912 - val_loss: 0.4172\nEpoch 10/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9359 - auc: 0.9842 - loss: 0.4289 - val_accuracy: 0.9602 - val_auc: 0.9923 - val_loss: 0.3516\nEpoch 11/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9367 - auc: 0.9804 - loss: 0.3961 - val_accuracy: 0.9535 - val_auc: 0.9920 - val_loss: 0.3230\nEpoch 12/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9372 - auc: 0.9846 - loss: 0.3376 - val_accuracy: 0.9356 - val_auc: 0.9914 - val_loss: 0.3305\nEpoch 13/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9320 - auc: 0.9825 - loss: 0.3196 - val_accuracy: 0.9526 - val_auc: 0.9921 - val_loss: 0.2556\nEpoch 14/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9372 - auc: 0.9850 - loss: 0.2774 - val_accuracy: 0.9533 - val_auc: 0.9912 - val_loss: 0.2413\nEpoch 15/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9372 - auc: 0.9786 - loss: 0.2591 - val_accuracy: 0.9618 - val_auc: 0.9931 - val_loss: 0.2039\nEpoch 16/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9381 - auc: 0.9870 - loss: 0.2329 - val_accuracy: 0.9548 - val_auc: 0.9925 - val_loss: 0.1933\nEpoch 17/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9423 - auc: 0.9853 - loss: 0.2328 - val_accuracy: 0.9625 - val_auc: 0.9936 - val_loss: 0.1738\nEpoch 18/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9443 - auc: 0.9873 - loss: 0.2018 - val_accuracy: 0.9540 - val_auc: 0.9933 - val_loss: 0.1906\nEpoch 19/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9374 - auc: 0.9850 - loss: 0.2098 - val_accuracy: 0.9771 - val_auc: 0.9930 - val_loss: 0.1409\nEpoch 20/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9380 - auc: 0.9838 - loss: 0.2100 - val_accuracy: 0.9560 - val_auc: 0.9941 - val_loss: 0.1586\nEpoch 21/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9417 - auc: 0.9866 - loss: 0.1845 - val_accuracy: 0.9477 - val_auc: 0.9934 - val_loss: 0.1721\nEpoch 22/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9442 - auc: 0.9875 - loss: 0.1774 - val_accuracy: 0.9677 - val_auc: 0.9941 - val_loss: 0.1377\nEpoch 23/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9445 - auc: 0.9832 - loss: 0.1800 - val_accuracy: 0.9513 - val_auc: 0.9930 - val_loss: 0.1453\nEpoch 24/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9434 - auc: 0.9884 - loss: 0.1662 - val_accuracy: 0.9461 - val_auc: 0.9928 - val_loss: 0.1667\nEpoch 25/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9445 - auc: 0.9878 - loss: 0.1596 - val_accuracy: 0.9410 - val_auc: 0.9941 - val_loss: 0.1644\nEpoch 26/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9383 - auc: 0.9887 - loss: 0.1573 - val_accuracy: 0.9728 - val_auc: 0.9932 - val_loss: 0.1165\nEpoch 27/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9465 - auc: 0.9867 - loss: 0.1710 - val_accuracy: 0.9598 - val_auc: 0.9935 - val_loss: 0.1246\nEpoch 28/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9476 - auc: 0.9890 - loss: 0.1482 - val_accuracy: 0.9547 - val_auc: 0.9950 - val_loss: 0.1330\nEpoch 29/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9378 - auc: 0.9823 - loss: 0.1689 - val_accuracy: 0.9744 - val_auc: 0.9934 - val_loss: 0.1104\nEpoch 30/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9476 - auc: 0.9891 - loss: 0.1454 - val_accuracy: 0.9370 - val_auc: 0.9929 - val_loss: 0.1628\nEpoch 31/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9446 - auc: 0.9880 - loss: 0.1574 - val_accuracy: 0.9433 - val_auc: 0.9924 - val_loss: 0.1539\nEpoch 32/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9386 - auc: 0.9839 - loss: 0.1642 - val_accuracy: 0.9716 - val_auc: 0.9946 - val_loss: 0.1107\nEpoch 33/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9445 - auc: 0.9872 - loss: 0.1518 - val_accuracy: 0.9367 - val_auc: 0.9924 - val_loss: 0.1564\nEpoch 34/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9394 - auc: 0.9860 - loss: 0.1606 - val_accuracy: 0.9717 - val_auc: 0.9940 - val_loss: 0.1030\nEpoch 35/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9460 - auc: 0.9895 - loss: 0.1438 - val_accuracy: 0.9630 - val_auc: 0.9945 - val_loss: 0.1171\nEpoch 36/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9468 - auc: 0.9868 - loss: 0.1556 - val_accuracy: 0.9740 - val_auc: 0.9951 - val_loss: 0.0941\nEpoch 37/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9435 - auc: 0.9875 - loss: 0.1586 - val_accuracy: 0.9728 - val_auc: 0.9948 - val_loss: 0.1000\nEpoch 38/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9461 - auc: 0.9883 - loss: 0.1504 - val_accuracy: 0.9653 - val_auc: 0.9942 - val_loss: 0.1165\nEpoch 39/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9419 - auc: 0.9864 - loss: 0.1643 - val_accuracy: 0.9598 - val_auc: 0.9939 - val_loss: 0.1241\nEpoch 40/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9416 - auc: 0.9890 - loss: 0.1434 - val_accuracy: 0.9613 - val_auc: 0.9945 - val_loss: 0.1217\nEpoch 41/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9455 - auc: 0.9878 - loss: 0.1601 - val_accuracy: 0.9617 - val_auc: 0.9943 - val_loss: 0.1164\nEpoch 42/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9463 - auc: 0.9888 - loss: 0.1484 - val_accuracy: 0.9481 - val_auc: 0.9942 - val_loss: 0.1593\nEpoch 43/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9452 - auc: 0.9889 - loss: 0.1425 - val_accuracy: 0.9649 - val_auc: 0.9935 - val_loss: 0.1182\nEpoch 44/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9457 - auc: 0.9889 - loss: 0.1442 - val_accuracy: 0.9758 - val_auc: 0.9945 - val_loss: 0.1023\nEpoch 45/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9520 - auc: 0.9892 - loss: 0.1366 - val_accuracy: 0.9503 - val_auc: 0.9928 - val_loss: 0.1488\nEpoch 46/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9409 - auc: 0.9870 - loss: 0.1610 - val_accuracy: 0.9611 - val_auc: 0.9941 - val_loss: 0.1127\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\nFold 2 - Best threshold: 0.860, F1-score: 0.7604\n\nTraining fold 3/5\nTraining set class distribution: [40454   738]\nValidation set class distribution: [10113   185]\nClass weights: {0: 0.5091214713007366, 1: 27.907859078590786}\nEpoch 1/60\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 5ms/step - accuracy: 0.9595 - auc: 0.7946 - loss: 2.8495 - val_accuracy: 0.9313 - val_auc: 0.9798 - val_loss: 1.6706\nEpoch 2/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9273 - auc: 0.9679 - loss: 1.6362 - val_accuracy: 0.9322 - val_auc: 0.9834 - val_loss: 1.3543\nEpoch 3/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9270 - auc: 0.9645 - loss: 1.3374 - val_accuracy: 0.9379 - val_auc: 0.9857 - val_loss: 1.1003\nEpoch 4/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9356 - auc: 0.9769 - loss: 1.0905 - val_accuracy: 0.9505 - val_auc: 0.9861 - val_loss: 0.8981\nEpoch 5/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9332 - auc: 0.9764 - loss: 0.9144 - val_accuracy: 0.9273 - val_auc: 0.9864 - val_loss: 0.8042\nEpoch 6/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9300 - auc: 0.9826 - loss: 0.7448 - val_accuracy: 0.9537 - val_auc: 0.9908 - val_loss: 0.6303\nEpoch 7/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9338 - auc: 0.9825 - loss: 0.6472 - val_accuracy: 0.9525 - val_auc: 0.9888 - val_loss: 0.5406\nEpoch 8/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9380 - auc: 0.9850 - loss: 0.5453 - val_accuracy: 0.9411 - val_auc: 0.9880 - val_loss: 0.4715\nEpoch 9/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9377 - auc: 0.9803 - loss: 0.4894 - val_accuracy: 0.9413 - val_auc: 0.9869 - val_loss: 0.4132\nEpoch 10/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9347 - auc: 0.9830 - loss: 0.4188 - val_accuracy: 0.9382 - val_auc: 0.9868 - val_loss: 0.3772\nEpoch 11/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9355 - auc: 0.9844 - loss: 0.3686 - val_accuracy: 0.9567 - val_auc: 0.9885 - val_loss: 0.3136\nEpoch 12/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9344 - auc: 0.9818 - loss: 0.3458 - val_accuracy: 0.9575 - val_auc: 0.9881 - val_loss: 0.2784\nEpoch 13/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9440 - auc: 0.9870 - loss: 0.2858 - val_accuracy: 0.9492 - val_auc: 0.9880 - val_loss: 0.2715\nEpoch 14/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9356 - auc: 0.9845 - loss: 0.2780 - val_accuracy: 0.9505 - val_auc: 0.9875 - val_loss: 0.2363\nEpoch 15/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9373 - auc: 0.9837 - loss: 0.2695 - val_accuracy: 0.9522 - val_auc: 0.9873 - val_loss: 0.2210\nEpoch 16/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9414 - auc: 0.9863 - loss: 0.2345 - val_accuracy: 0.9715 - val_auc: 0.9871 - val_loss: 0.1843\nEpoch 17/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9415 - auc: 0.9852 - loss: 0.2333 - val_accuracy: 0.9448 - val_auc: 0.9881 - val_loss: 0.2094\nEpoch 18/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9432 - auc: 0.9888 - loss: 0.1977 - val_accuracy: 0.9532 - val_auc: 0.9882 - val_loss: 0.1832\nEpoch 19/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9441 - auc: 0.9863 - loss: 0.2048 - val_accuracy: 0.9439 - val_auc: 0.9871 - val_loss: 0.1933\nEpoch 20/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9427 - auc: 0.9876 - loss: 0.1830 - val_accuracy: 0.9692 - val_auc: 0.9894 - val_loss: 0.1461\nEpoch 21/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9441 - auc: 0.9858 - loss: 0.1898 - val_accuracy: 0.9513 - val_auc: 0.9875 - val_loss: 0.1884\nEpoch 22/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9414 - auc: 0.9865 - loss: 0.1848 - val_accuracy: 0.9564 - val_auc: 0.9878 - val_loss: 0.1572\nEpoch 23/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9423 - auc: 0.9885 - loss: 0.1682 - val_accuracy: 0.9586 - val_auc: 0.9858 - val_loss: 0.1569\nEpoch 24/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9385 - auc: 0.9866 - loss: 0.1777 - val_accuracy: 0.9540 - val_auc: 0.9867 - val_loss: 0.1501\nEpoch 25/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9411 - auc: 0.9861 - loss: 0.1759 - val_accuracy: 0.9634 - val_auc: 0.9889 - val_loss: 0.1493\nEpoch 26/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9454 - auc: 0.9878 - loss: 0.1671 - val_accuracy: 0.9685 - val_auc: 0.9880 - val_loss: 0.1382\nEpoch 27/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9481 - auc: 0.9872 - loss: 0.1599 - val_accuracy: 0.9745 - val_auc: 0.9874 - val_loss: 0.1148\nEpoch 28/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9478 - auc: 0.9884 - loss: 0.1532 - val_accuracy: 0.9648 - val_auc: 0.9879 - val_loss: 0.1355\nEpoch 29/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9463 - auc: 0.9853 - loss: 0.1632 - val_accuracy: 0.9737 - val_auc: 0.9862 - val_loss: 0.1259\nEpoch 30/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9456 - auc: 0.9848 - loss: 0.1654 - val_accuracy: 0.9672 - val_auc: 0.9873 - val_loss: 0.1286\nEpoch 31/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9454 - auc: 0.9884 - loss: 0.1542 - val_accuracy: 0.9578 - val_auc: 0.9885 - val_loss: 0.1440\nEpoch 32/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9444 - auc: 0.9881 - loss: 0.1635 - val_accuracy: 0.9676 - val_auc: 0.9870 - val_loss: 0.1186\nEpoch 33/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9508 - auc: 0.9890 - loss: 0.1450 - val_accuracy: 0.9767 - val_auc: 0.9863 - val_loss: 0.1143\nEpoch 34/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9501 - auc: 0.9850 - loss: 0.1503 - val_accuracy: 0.9475 - val_auc: 0.9874 - val_loss: 0.1519\nEpoch 35/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9434 - auc: 0.9873 - loss: 0.1530 - val_accuracy: 0.9546 - val_auc: 0.9889 - val_loss: 0.1353\nEpoch 36/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9506 - auc: 0.9910 - loss: 0.1315 - val_accuracy: 0.9662 - val_auc: 0.9898 - val_loss: 0.1213\nEpoch 37/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9449 - auc: 0.9875 - loss: 0.1547 - val_accuracy: 0.9669 - val_auc: 0.9902 - val_loss: 0.1155\nEpoch 38/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9426 - auc: 0.9879 - loss: 0.1597 - val_accuracy: 0.9581 - val_auc: 0.9890 - val_loss: 0.1283\nEpoch 39/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9483 - auc: 0.9900 - loss: 0.1372 - val_accuracy: 0.9495 - val_auc: 0.9871 - val_loss: 0.1404\nEpoch 40/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9480 - auc: 0.9850 - loss: 0.1531 - val_accuracy: 0.9360 - val_auc: 0.9883 - val_loss: 0.1905\nEpoch 41/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9484 - auc: 0.9896 - loss: 0.1364 - val_accuracy: 0.9741 - val_auc: 0.9859 - val_loss: 0.1064\nEpoch 42/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9476 - auc: 0.9882 - loss: 0.1436 - val_accuracy: 0.9639 - val_auc: 0.9891 - val_loss: 0.1269\nEpoch 43/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9494 - auc: 0.9886 - loss: 0.1458 - val_accuracy: 0.9518 - val_auc: 0.9891 - val_loss: 0.1397\nEpoch 44/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9411 - auc: 0.9872 - loss: 0.1545 - val_accuracy: 0.9729 - val_auc: 0.9889 - val_loss: 0.1041\nEpoch 45/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9498 - auc: 0.9882 - loss: 0.1455 - val_accuracy: 0.9543 - val_auc: 0.9893 - val_loss: 0.1341\nEpoch 46/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9445 - auc: 0.9879 - loss: 0.1529 - val_accuracy: 0.9610 - val_auc: 0.9889 - val_loss: 0.1238\nEpoch 47/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9490 - auc: 0.9895 - loss: 0.1382 - val_accuracy: 0.9662 - val_auc: 0.9899 - val_loss: 0.1120\nEpoch 48/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9471 - auc: 0.9901 - loss: 0.1346 - val_accuracy: 0.9531 - val_auc: 0.9893 - val_loss: 0.1416\nEpoch 49/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9449 - auc: 0.9843 - loss: 0.1523 - val_accuracy: 0.9626 - val_auc: 0.9898 - val_loss: 0.1166\nEpoch 50/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9500 - auc: 0.9891 - loss: 0.1412 - val_accuracy: 0.9751 - val_auc: 0.9893 - val_loss: 0.1054\nEpoch 51/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9522 - auc: 0.9893 - loss: 0.1368 - val_accuracy: 0.9545 - val_auc: 0.9889 - val_loss: 0.1385\nEpoch 52/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9506 - auc: 0.9889 - loss: 0.1388 - val_accuracy: 0.9638 - val_auc: 0.9894 - val_loss: 0.1093\nEpoch 53/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9501 - auc: 0.9892 - loss: 0.1434 - val_accuracy: 0.9387 - val_auc: 0.9877 - val_loss: 0.1673\nEpoch 54/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9459 - auc: 0.9890 - loss: 0.1474 - val_accuracy: 0.9726 - val_auc: 0.9899 - val_loss: 0.1027\nEpoch 55/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9474 - auc: 0.9897 - loss: 0.1376 - val_accuracy: 0.9640 - val_auc: 0.9896 - val_loss: 0.1158\nEpoch 56/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9466 - auc: 0.9904 - loss: 0.1317 - val_accuracy: 0.9648 - val_auc: 0.9902 - val_loss: 0.1206\nEpoch 57/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9471 - auc: 0.9905 - loss: 0.1302 - val_accuracy: 0.9647 - val_auc: 0.9890 - val_loss: 0.1251\nEpoch 58/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9504 - auc: 0.9900 - loss: 0.1346 - val_accuracy: 0.9671 - val_auc: 0.9890 - val_loss: 0.1056\nEpoch 59/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9457 - auc: 0.9878 - loss: 0.1538 - val_accuracy: 0.9646 - val_auc: 0.9892 - val_loss: 0.1185\nEpoch 60/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9464 - auc: 0.9891 - loss: 0.1397 - val_accuracy: 0.9671 - val_auc: 0.9887 - val_loss: 0.1089\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\nFold 3 - Best threshold: 0.880, F1-score: 0.7305\n\nTraining fold 4/5\nTraining set class distribution: [40454   738]\nValidation set class distribution: [10113   185]\nClass weights: {0: 0.5091214713007366, 1: 27.907859078590786}\nEpoch 1/60\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 5ms/step - accuracy: 0.9632 - auc: 0.6864 - loss: 3.2213 - val_accuracy: 0.9312 - val_auc: 0.9744 - val_loss: 1.6667\nEpoch 2/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9255 - auc: 0.9650 - loss: 1.6713 - val_accuracy: 0.9254 - val_auc: 0.9808 - val_loss: 1.3818\nEpoch 3/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9251 - auc: 0.9753 - loss: 1.3608 - val_accuracy: 0.9273 - val_auc: 0.9814 - val_loss: 1.1523\nEpoch 4/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9233 - auc: 0.9741 - loss: 1.1517 - val_accuracy: 0.9346 - val_auc: 0.9824 - val_loss: 0.9761\nEpoch 5/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9283 - auc: 0.9781 - loss: 0.9679 - val_accuracy: 0.9363 - val_auc: 0.9834 - val_loss: 0.8298\nEpoch 6/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9313 - auc: 0.9826 - loss: 0.8054 - val_accuracy: 0.9534 - val_auc: 0.9845 - val_loss: 0.6725\nEpoch 7/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9379 - auc: 0.9822 - loss: 0.6917 - val_accuracy: 0.9550 - val_auc: 0.9842 - val_loss: 0.5701\nEpoch 8/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9347 - auc: 0.9827 - loss: 0.5954 - val_accuracy: 0.9518 - val_auc: 0.9846 - val_loss: 0.4939\nEpoch 9/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9350 - auc: 0.9832 - loss: 0.5201 - val_accuracy: 0.9560 - val_auc: 0.9850 - val_loss: 0.4166\nEpoch 10/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9372 - auc: 0.9828 - loss: 0.4570 - val_accuracy: 0.9540 - val_auc: 0.9840 - val_loss: 0.3726\nEpoch 11/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9421 - auc: 0.9799 - loss: 0.4079 - val_accuracy: 0.9455 - val_auc: 0.9818 - val_loss: 0.3377\nEpoch 12/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9388 - auc: 0.9862 - loss: 0.3498 - val_accuracy: 0.9464 - val_auc: 0.9835 - val_loss: 0.3033\nEpoch 13/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9392 - auc: 0.9878 - loss: 0.3070 - val_accuracy: 0.9646 - val_auc: 0.9828 - val_loss: 0.2454\nEpoch 14/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9459 - auc: 0.9894 - loss: 0.2671 - val_accuracy: 0.9575 - val_auc: 0.9834 - val_loss: 0.2379\nEpoch 15/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9388 - auc: 0.9847 - loss: 0.2790 - val_accuracy: 0.9624 - val_auc: 0.9834 - val_loss: 0.2086\nEpoch 16/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9451 - auc: 0.9884 - loss: 0.2348 - val_accuracy: 0.9536 - val_auc: 0.9848 - val_loss: 0.2088\nEpoch 17/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9379 - auc: 0.9848 - loss: 0.2396 - val_accuracy: 0.9504 - val_auc: 0.9845 - val_loss: 0.1948\nEpoch 18/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9404 - auc: 0.9878 - loss: 0.2117 - val_accuracy: 0.9550 - val_auc: 0.9838 - val_loss: 0.1785\nEpoch 19/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9382 - auc: 0.9868 - loss: 0.2077 - val_accuracy: 0.9670 - val_auc: 0.9849 - val_loss: 0.1540\nEpoch 20/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9449 - auc: 0.9887 - loss: 0.1871 - val_accuracy: 0.9554 - val_auc: 0.9851 - val_loss: 0.1579\nEpoch 21/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9471 - auc: 0.9901 - loss: 0.1696 - val_accuracy: 0.9633 - val_auc: 0.9851 - val_loss: 0.1480\nEpoch 22/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9378 - auc: 0.9837 - loss: 0.2044 - val_accuracy: 0.9518 - val_auc: 0.9839 - val_loss: 0.1551\nEpoch 23/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9438 - auc: 0.9890 - loss: 0.1658 - val_accuracy: 0.9695 - val_auc: 0.9834 - val_loss: 0.1282\nEpoch 24/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9406 - auc: 0.9860 - loss: 0.1877 - val_accuracy: 0.9615 - val_auc: 0.9834 - val_loss: 0.1379\nEpoch 25/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9433 - auc: 0.9885 - loss: 0.1622 - val_accuracy: 0.9597 - val_auc: 0.9851 - val_loss: 0.1311\nEpoch 26/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9453 - auc: 0.9876 - loss: 0.1704 - val_accuracy: 0.9441 - val_auc: 0.9830 - val_loss: 0.1544\nEpoch 27/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9468 - auc: 0.9887 - loss: 0.1530 - val_accuracy: 0.9592 - val_auc: 0.9846 - val_loss: 0.1306\nEpoch 28/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9457 - auc: 0.9901 - loss: 0.1464 - val_accuracy: 0.9714 - val_auc: 0.9863 - val_loss: 0.1059\nEpoch 29/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9499 - auc: 0.9901 - loss: 0.1463 - val_accuracy: 0.9716 - val_auc: 0.9836 - val_loss: 0.1069\nEpoch 30/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9492 - auc: 0.9907 - loss: 0.1432 - val_accuracy: 0.9591 - val_auc: 0.9850 - val_loss: 0.1184\nEpoch 31/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9496 - auc: 0.9881 - loss: 0.1534 - val_accuracy: 0.9490 - val_auc: 0.9844 - val_loss: 0.1498\nEpoch 32/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9478 - auc: 0.9903 - loss: 0.1427 - val_accuracy: 0.9640 - val_auc: 0.9856 - val_loss: 0.1169\nEpoch 33/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9512 - auc: 0.9905 - loss: 0.1367 - val_accuracy: 0.9638 - val_auc: 0.9847 - val_loss: 0.1099\nEpoch 34/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9505 - auc: 0.9905 - loss: 0.1399 - val_accuracy: 0.9435 - val_auc: 0.9847 - val_loss: 0.1605\nEpoch 35/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9440 - auc: 0.9892 - loss: 0.1507 - val_accuracy: 0.9739 - val_auc: 0.9846 - val_loss: 0.0926\nEpoch 36/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9525 - auc: 0.9899 - loss: 0.1392 - val_accuracy: 0.9722 - val_auc: 0.9849 - val_loss: 0.1015\nEpoch 37/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9484 - auc: 0.9905 - loss: 0.1374 - val_accuracy: 0.9729 - val_auc: 0.9851 - val_loss: 0.0976\nEpoch 38/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9450 - auc: 0.9887 - loss: 0.1559 - val_accuracy: 0.9739 - val_auc: 0.9855 - val_loss: 0.0920\nEpoch 39/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9482 - auc: 0.9889 - loss: 0.1476 - val_accuracy: 0.9521 - val_auc: 0.9854 - val_loss: 0.1258\nEpoch 40/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9466 - auc: 0.9897 - loss: 0.1324 - val_accuracy: 0.9569 - val_auc: 0.9851 - val_loss: 0.1145\nEpoch 41/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9468 - auc: 0.9887 - loss: 0.1513 - val_accuracy: 0.9603 - val_auc: 0.9873 - val_loss: 0.1059\nEpoch 42/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9459 - auc: 0.9905 - loss: 0.1330 - val_accuracy: 0.9633 - val_auc: 0.9852 - val_loss: 0.1095\nEpoch 43/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9470 - auc: 0.9903 - loss: 0.1324 - val_accuracy: 0.9606 - val_auc: 0.9855 - val_loss: 0.1032\nEpoch 44/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9464 - auc: 0.9895 - loss: 0.1418 - val_accuracy: 0.9615 - val_auc: 0.9852 - val_loss: 0.1105\nEpoch 45/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9416 - auc: 0.9891 - loss: 0.1433 - val_accuracy: 0.9466 - val_auc: 0.9848 - val_loss: 0.1362\nEpoch 46/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9480 - auc: 0.9900 - loss: 0.1371 - val_accuracy: 0.9689 - val_auc: 0.9847 - val_loss: 0.1033\nEpoch 47/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9457 - auc: 0.9898 - loss: 0.1401 - val_accuracy: 0.9525 - val_auc: 0.9846 - val_loss: 0.1304\nEpoch 48/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9492 - auc: 0.9889 - loss: 0.1439 - val_accuracy: 0.9540 - val_auc: 0.9843 - val_loss: 0.1198\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\nFold 4 - Best threshold: 0.880, F1-score: 0.7128\n\nTraining fold 5/5\nTraining set class distribution: [40454   738]\nValidation set class distribution: [10113   185]\nClass weights: {0: 0.5091214713007366, 1: 27.907859078590786}\nEpoch 1/60\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 10ms/step - accuracy: 0.9581 - auc: 0.7974 - loss: 2.7792 - val_accuracy: 0.9342 - val_auc: 0.9666 - val_loss: 1.6112\nEpoch 2/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9278 - auc: 0.9605 - loss: 1.6103 - val_accuracy: 0.9325 - val_auc: 0.9738 - val_loss: 1.3297\nEpoch 3/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9251 - auc: 0.9705 - loss: 1.3129 - val_accuracy: 0.9359 - val_auc: 0.9768 - val_loss: 1.0926\nEpoch 4/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9283 - auc: 0.9718 - loss: 1.0966 - val_accuracy: 0.9486 - val_auc: 0.9847 - val_loss: 0.8886\nEpoch 5/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9325 - auc: 0.9797 - loss: 0.8997 - val_accuracy: 0.9480 - val_auc: 0.9885 - val_loss: 0.7521\nEpoch 6/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9316 - auc: 0.9805 - loss: 0.7640 - val_accuracy: 0.9502 - val_auc: 0.9907 - val_loss: 0.6333\nEpoch 7/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9344 - auc: 0.9801 - loss: 0.6599 - val_accuracy: 0.9589 - val_auc: 0.9904 - val_loss: 0.5290\nEpoch 8/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9354 - auc: 0.9813 - loss: 0.5665 - val_accuracy: 0.9483 - val_auc: 0.9914 - val_loss: 0.4740\nEpoch 9/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9340 - auc: 0.9785 - loss: 0.4921 - val_accuracy: 0.9476 - val_auc: 0.9907 - val_loss: 0.4128\nEpoch 10/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9352 - auc: 0.9834 - loss: 0.4277 - val_accuracy: 0.9468 - val_auc: 0.9927 - val_loss: 0.3555\nEpoch 11/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9365 - auc: 0.9832 - loss: 0.3802 - val_accuracy: 0.9486 - val_auc: 0.9926 - val_loss: 0.3159\nEpoch 12/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9364 - auc: 0.9860 - loss: 0.3299 - val_accuracy: 0.9547 - val_auc: 0.9916 - val_loss: 0.2737\nEpoch 13/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9405 - auc: 0.9792 - loss: 0.2934 - val_accuracy: 0.9537 - val_auc: 0.9927 - val_loss: 0.2433\nEpoch 14/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9360 - auc: 0.9849 - loss: 0.2751 - val_accuracy: 0.9711 - val_auc: 0.9928 - val_loss: 0.2094\nEpoch 15/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9442 - auc: 0.9868 - loss: 0.2467 - val_accuracy: 0.9770 - val_auc: 0.9928 - val_loss: 0.1840\nEpoch 16/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9418 - auc: 0.9847 - loss: 0.2393 - val_accuracy: 0.9543 - val_auc: 0.9928 - val_loss: 0.1926\nEpoch 17/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9365 - auc: 0.9851 - loss: 0.2251 - val_accuracy: 0.9614 - val_auc: 0.9934 - val_loss: 0.1763\nEpoch 18/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9443 - auc: 0.9883 - loss: 0.1971 - val_accuracy: 0.9767 - val_auc: 0.9930 - val_loss: 0.1450\nEpoch 19/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9493 - auc: 0.9875 - loss: 0.1890 - val_accuracy: 0.9446 - val_auc: 0.9917 - val_loss: 0.1815\nEpoch 20/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9412 - auc: 0.9883 - loss: 0.1792 - val_accuracy: 0.9573 - val_auc: 0.9925 - val_loss: 0.1610\nEpoch 21/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9468 - auc: 0.9893 - loss: 0.1629 - val_accuracy: 0.9685 - val_auc: 0.9933 - val_loss: 0.1312\nEpoch 22/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9453 - auc: 0.9880 - loss: 0.1709 - val_accuracy: 0.9581 - val_auc: 0.9910 - val_loss: 0.1555\nEpoch 23/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9422 - auc: 0.9860 - loss: 0.1796 - val_accuracy: 0.9560 - val_auc: 0.9934 - val_loss: 0.1421\nEpoch 24/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9440 - auc: 0.9834 - loss: 0.1750 - val_accuracy: 0.9526 - val_auc: 0.9922 - val_loss: 0.1422\nEpoch 25/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9425 - auc: 0.9853 - loss: 0.1573 - val_accuracy: 0.9579 - val_auc: 0.9935 - val_loss: 0.1367\nEpoch 26/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9446 - auc: 0.9791 - loss: 0.1735 - val_accuracy: 0.9602 - val_auc: 0.9933 - val_loss: 0.1312\nEpoch 27/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9481 - auc: 0.9892 - loss: 0.1470 - val_accuracy: 0.9521 - val_auc: 0.9939 - val_loss: 0.1360\nEpoch 28/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9484 - auc: 0.9901 - loss: 0.1446 - val_accuracy: 0.9581 - val_auc: 0.9924 - val_loss: 0.1349\nEpoch 29/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9452 - auc: 0.9889 - loss: 0.1498 - val_accuracy: 0.9734 - val_auc: 0.9937 - val_loss: 0.1080\nEpoch 30/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9446 - auc: 0.9877 - loss: 0.1568 - val_accuracy: 0.9496 - val_auc: 0.9934 - val_loss: 0.1521\nEpoch 31/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9488 - auc: 0.9892 - loss: 0.1456 - val_accuracy: 0.9402 - val_auc: 0.9933 - val_loss: 0.1577\nEpoch 32/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9423 - auc: 0.9883 - loss: 0.1509 - val_accuracy: 0.9349 - val_auc: 0.9910 - val_loss: 0.1674\nEpoch 33/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9442 - auc: 0.9860 - loss: 0.1450 - val_accuracy: 0.9552 - val_auc: 0.9910 - val_loss: 0.1531\nEpoch 34/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9446 - auc: 0.9889 - loss: 0.1432 - val_accuracy: 0.9449 - val_auc: 0.9933 - val_loss: 0.1459\nEpoch 35/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9432 - auc: 0.9855 - loss: 0.1586 - val_accuracy: 0.9543 - val_auc: 0.9936 - val_loss: 0.1255\nEpoch 36/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9492 - auc: 0.9851 - loss: 0.1427 - val_accuracy: 0.9544 - val_auc: 0.9935 - val_loss: 0.1252\nEpoch 37/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9413 - auc: 0.9888 - loss: 0.1465 - val_accuracy: 0.9595 - val_auc: 0.9935 - val_loss: 0.1196\nEpoch 38/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9448 - auc: 0.9864 - loss: 0.1631 - val_accuracy: 0.9569 - val_auc: 0.9935 - val_loss: 0.1174\nEpoch 39/60\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9506 - auc: 0.9899 - loss: 0.1339 - val_accuracy: 0.9535 - val_auc: 0.9932 - val_loss: 0.1375\n\u001B[1m322/322\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\nFold 5 - Best threshold: 0.880, F1-score: 0.6943\n\nCross-validation summary:\nMean F1-score: 0.7135 ± 0.0309\nMean threshold: 0.8520 ± 0.0466\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 226
  },
  {
   "cell_type": "code",
   "source": "def make_ensemble_predictions(models, scalers, thresholds, test_data, features_for_modelling):\n    all_predictions = []\n    \n    for model, scaler, threshold in zip(models, scalers, thresholds):\n        X_test_scaled = scaler.transform(test_data[features_for_modelling])\n        pred_proba = model.predict(X_test_scaled)\n        pred_binary = (pred_proba > threshold).astype(int)\n        all_predictions.append(pred_binary)\n    \n    ensemble_predictions = np.round(np.mean(all_predictions, axis=0)).astype(int)\n    \n    print(\"\\nEnsemble prediction distribution:\")\n    print(np.bincount(ensemble_predictions.ravel()))\n    \n    output = pd.DataFrame({\n        'ID': test_data['ID'],\n        'target': ensemble_predictions.ravel()\n    })\n    \n    return output",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-30T21:09:51.930957Z",
     "iopub.execute_input": "2024-12-30T21:09:51.931329Z",
     "iopub.status.idle": "2024-12-30T21:09:51.938011Z",
     "shell.execute_reply.started": "2024-12-30T21:09:51.931300Z",
     "shell.execute_reply": "2024-12-30T21:09:51.936772Z"
    }
   },
   "outputs": [],
   "execution_count": 227
  },
  {
   "cell_type": "code",
   "source": "output = make_ensemble_predictions(\n    models, scalers, thresholds, test_df, features_for_modelling\n)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-30T21:09:51.939388Z",
     "iopub.execute_input": "2024-12-30T21:09:51.939761Z",
     "iopub.status.idle": "2024-12-30T21:09:57.036855Z",
     "shell.execute_reply.started": "2024-12-30T21:09:51.939731Z",
     "shell.execute_reply": "2024-12-30T21:09:57.035576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001B[1m582/582\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n\u001B[1m582/582\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n\u001B[1m582/582\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n\u001B[1m582/582\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n\u001B[1m582/582\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n\nEnsemble prediction distribution:\n[17900   694]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 228
  },
  {
   "cell_type": "code",
   "source": "output.to_csv('Test_predictions.csv', index=False)\nprint(\"Predictions saved to Test_predictions.csv\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-30T21:09:57.038042Z",
     "iopub.execute_input": "2024-12-30T21:09:57.038453Z",
     "iopub.status.idle": "2024-12-30T21:09:57.068888Z",
     "shell.execute_reply.started": "2024-12-30T21:09:57.038411Z",
     "shell.execute_reply": "2024-12-30T21:09:57.067661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Predictions saved to Test_predictions.csv\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 229
  },
  {
   "cell_type": "code",
   "source": [
    "histories = []\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "avg_loss = np.mean([h.history['loss'] for h in histories], axis=0)\n",
    "avg_val_loss = np.mean([h.history['val_loss'] for h in histories], axis=0)\n",
    "avg_auc = np.mean([h.history['auc'] for h in histories], axis=0)\n",
    "avg_val_auc = np.mean([h.history['val_auc'] for h in histories], axis=0)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(avg_loss, label='Training Loss')\n",
    "plt.plot(avg_val_loss, label='Validation Loss')\n",
    "plt.title('Average Loss Across Folds')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(avg_auc, label='Training AUC')\n",
    "plt.plot(avg_val_auc, label='Validation AUC')\n",
    "plt.title('Average AUC Across Folds')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for i, f1 in enumerate(f1_scores):\n",
    "    print(f\"Fold {i+1} - F1 Score: {f1:.4f}, Threshold: {thresholds[i]:.4f}\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2024-12-30T21:09:57.070256Z",
     "iopub.execute_input": "2024-12-30T21:09:57.070632Z",
     "iopub.status.idle": "2024-12-30T21:09:57.098700Z",
     "shell.execute_reply.started": "2024-12-30T21:09:57.070593Z",
     "shell.execute_reply": "2024-12-30T21:09:57.097086Z"
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-230-0fc9dd20443d>\u001B[0m in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# Inside the fold loop, after model.fit:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mhistories\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# Store the history object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;31m# Then for visualization after training:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'history' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error"
    }
   ],
   "execution_count": 230
  }
 ]
}
