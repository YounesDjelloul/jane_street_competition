{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nfrom sklearn.model_selection import train_test_split\nimport gc\nfrom sklearn.metrics import r2_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T19:59:57.690372Z","iopub.execute_input":"2024-12-25T19:59:57.690812Z","iopub.status.idle":"2024-12-25T19:59:57.695759Z","shell.execute_reply.started":"2024-12-25T19:59:57.690780Z","shell.execute_reply":"2024-12-25T19:59:57.694418Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"str1 = '../input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id='\nstr2 = '/part-0.parquet'\nfile_paths = [f\"{str1}{i}{str2}\" for i in range(4)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T19:59:57.697212Z","iopub.execute_input":"2024-12-25T19:59:57.697584Z","iopub.status.idle":"2024-12-25T19:59:57.718356Z","shell.execute_reply.started":"2024-12-25T19:59:57.697554Z","shell.execute_reply":"2024-12-25T19:59:57.717000Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"class FinancialDataset(Dataset):\n    def __init__(self, df):\n\n        columns_to_drop = ['feature_21', 'feature_26', 'feature_27', 'feature_31']\n        self.feature_cols = ([f'feature_{i:02d}' for i in range(79) if f'feature_{i:02d}' not in columns_to_drop] +\n                             ['responder_0', 'responder_1', 'responder_2', 'responder_3',\n                              'responder_4', 'responder_5', 'responder_7', 'responder_8'])\n        \n        self.features = df[self.feature_cols].values\n        self.targets = df['responder_6'].values\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        return torch.FloatTensor(self.features[idx]), torch.FloatTensor([self.targets[idx]])\n        \nclass FinancialNN(torch.nn.Module):\n    def __init__(self, input_size):\n        super().__init__()\n        self.network = torch.nn.Sequential(\n            torch.nn.BatchNorm1d(input_size),\n            torch.nn.Linear(input_size, 512),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm1d(512),\n            torch.nn.Dropout(0.3),\n            torch.nn.Linear(512, 256),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm1d(256),\n            torch.nn.Dropout(0.3),\n            torch.nn.Linear(256, 128),\n            torch.nn.ReLU(),\n            torch.nn.BatchNorm1d(128),\n            torch.nn.Dropout(0.3),\n            torch.nn.Linear(128, 1)\n        )\n        \n    def forward(self, x):\n        return self.network(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T19:59:57.720597Z","iopub.execute_input":"2024-12-25T19:59:57.720930Z","iopub.status.idle":"2024-12-25T19:59:57.742445Z","shell.execute_reply.started":"2024-12-25T19:59:57.720901Z","shell.execute_reply":"2024-12-25T19:59:57.741501Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def load_partition(partition_id):\n    file_path = f\"../input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id={partition_id}/part-0.parquet\"\n    df = pd.read_parquet(file_path)\n\n    columns_to_drop = ['feature_21', 'feature_26', 'feature_27', 'feature_31']\n    feature_cols = ([f'feature_{i:02d}' for i in range(79) if f'feature_{i:02d}' not in columns_to_drop] +\n                         ['responder_0', 'responder_1', 'responder_2', 'responder_3',\n                          'responder_4', 'responder_5', 'responder_7', 'responder_8'])\n\n    for col in feature_cols:\n        median_val = df[col].median()\n        \n        if df[col].isna().any():\n            df[col] = df[col].fillna(median_val if not pd.isna(median_val) else 0)\n    \n    df = df.drop(columns=columns_to_drop)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T19:59:57.743776Z","iopub.execute_input":"2024-12-25T19:59:57.744158Z","iopub.status.idle":"2024-12-25T19:59:57.768774Z","shell.execute_reply.started":"2024-12-25T19:59:57.744126Z","shell.execute_reply":"2024-12-25T19:59:57.767574Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def train_with_partitions(model, partition_ids, epochs_per_partition=2, lr=0.0005):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n\n    model = model.to(device)\n    criterion = torch.nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n\n    best_val_loss = float('inf')\n\n    for partition_id in partition_ids:\n        print(f\"Loading Partition: {partition_id}\")\n        df = load_partition(partition_id)\n        train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n        \n        train_dataset = FinancialDataset(train_df)\n        val_dataset = FinancialDataset(val_df)\n        \n        train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n        val_loader = DataLoader(val_dataset, batch_size=1024)\n        \n        print(f\"Training on Partition: {partition_id}\")\n        for epoch in range(epochs_per_partition):\n            model.train()\n            train_loss = 0\n            for batch_features, batch_targets in train_loader:\n                batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n                \n                optimizer.zero_grad()\n                outputs = model(batch_features)\n                loss = criterion(outputs, batch_targets)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                optimizer.step()\n                \n                train_loss += loss.item()\n    \n            model.eval()\n            val_loss = 0\n            all_preds = []\n            all_targets = []\n            with torch.no_grad():\n                for batch_features, batch_targets in val_loader:\n                    batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n                    outputs = model(batch_features)\n                    val_loss += criterion(outputs, batch_targets).item()\n    \n                    all_preds.append(outputs.cpu().numpy())\n                    all_targets.append(batch_targets.cpu().numpy())\n    \n            all_preds = np.concatenate(all_preds, axis=0)\n            all_targets = np.concatenate(all_targets, axis=0)\n    \n            r2 = r2_score(all_targets, all_preds)\n            \n            train_loss /= len(train_loader)\n            val_loss /= len(val_loader)\n    \n            print(f'Partition {partition_id} - Epoch {epoch + 1}:')\n            print(f'  Train Loss: {train_loss:.6f}')\n            print(f'  Val Loss: {val_loss:.6f}')\n            print(f'  RÂ²: {r2:.4f}')\n            \n            scheduler.step(val_loss)\n            \n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                torch.save(model.state_dict(), 'full_model.pth')\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T19:59:57.770072Z","iopub.execute_input":"2024-12-25T19:59:57.770378Z","iopub.status.idle":"2024-12-25T19:59:57.795858Z","shell.execute_reply.started":"2024-12-25T19:59:57.770352Z","shell.execute_reply":"2024-12-25T19:59:57.794710Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"sample_partition_id = 0\nsample_df = load_partition(sample_partition_id)\ntrain_sample, _ = train_test_split(sample_df, test_size=0.2, random_state=42)\n\ntrain_sample_dataset = FinancialDataset(train_sample)\ninput_size = len(train_sample_dataset.feature_cols)\n\nmodel = FinancialNN(input_size)\n\npartition_ids = list(range(10))\ntrained_model = train_with_partitions(model, partition_ids, epochs_per_partition=2, lr=0.0005)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T19:59:57.797161Z","iopub.execute_input":"2024-12-25T19:59:57.797741Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/numpy/lib/nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n/usr/local/lib/python3.10/dist-packages/numpy/lib/nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n/usr/local/lib/python3.10/dist-packages/numpy/lib/nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n/usr/local/lib/python3.10/dist-packages/numpy/lib/nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n/usr/local/lib/python3.10/dist-packages/numpy/lib/nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n","output_type":"stream"},{"name":"stdout","text":"Using device: cpu\nLoading Partition: 0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/numpy/lib/nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n/usr/local/lib/python3.10/dist-packages/numpy/lib/nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n/usr/local/lib/python3.10/dist-packages/numpy/lib/nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n/usr/local/lib/python3.10/dist-packages/numpy/lib/nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n/usr/local/lib/python3.10/dist-packages/numpy/lib/nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n","output_type":"stream"},{"name":"stdout","text":"Training on Partition: 0\n","output_type":"stream"}],"execution_count":null}]}